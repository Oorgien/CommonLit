{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "monetary-fishing",
   "metadata": {
    "papermill": {
     "duration": 0.019172,
     "end_time": "2021-06-09T10:28:22.185792",
     "exception": false,
     "start_time": "2021-06-09T10:28:22.166620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook uses below given notebooks to make predictions.\n",
    "\n",
    "1. LB 0.468 https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-infer-3\n",
    "2. LB 0.474 https://www.kaggle.com/maunish/clrp-roberta-svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d2627",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "solar-attention",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-09T10:28:22.234780Z",
     "iopub.status.busy": "2021-06-09T10:28:22.234165Z",
     "iopub.status.idle": "2021-06-09T10:28:28.540072Z",
     "shell.execute_reply": "2021-06-09T10:28:28.539126Z",
     "shell.execute_reply.started": "2021-06-09T10:10:00.916895Z"
    },
    "papermill": {
     "duration": 6.336567,
     "end_time": "2021-06-09T10:28:28.540221",
     "exception": false,
     "start_time": "2021-06-09T10:28:22.203654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (AutoModel, AutoTokenizer, \n",
    "                          AutoModelForSequenceClassification)\n",
    "from transformers import (RobertaTokenizer, RobertaModel)\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "y_ = Fore.YELLOW\n",
    "r_ = Fore.RED\n",
    "g_ = Fore.GREEN\n",
    "b_ = Fore.BLUE\n",
    "m_ = Fore.MAGENTA\n",
    "c_ = Fore.CYAN\n",
    "sr_ = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b37610",
   "metadata": {},
   "source": [
    "# Data analysys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ideal-copying",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:28:28.584231Z",
     "iopub.status.busy": "2021-06-09T10:28:28.583736Z",
     "iopub.status.idle": "2021-06-09T10:28:28.693183Z",
     "shell.execute_reply": "2021-06-09T10:28:28.692696Z",
     "shell.execute_reply.started": "2021-06-09T10:10:07.674205Z"
    },
    "papermill": {
     "duration": 0.135314,
     "end_time": "2021-06-09T10:28:28.693304",
     "exception": false,
     "start_time": "2021-06-09T10:28:28.557990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "sample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
    "\n",
    "num_bins = int(np.floor(1 + np.log2(len(train_data))))\n",
    "train_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n",
    "\n",
    "target = train_data['target'].to_numpy()\n",
    "target_normed = (target - np.mean(target))/np.var(target)\n",
    "bins = train_data.bins.to_numpy()\n",
    "\n",
    "def rmse_score(y_true,y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d149407c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (-0.533, -0.0845]\n",
       "1       (-0.533, -0.0845]\n",
       "2        (-0.982, -0.533]\n",
       "3        (-1.431, -0.982]\n",
       "4        (-0.0845, 0.364]\n",
       "              ...        \n",
       "2829       (1.262, 1.711]\n",
       "2830     (-0.0845, 0.364]\n",
       "2831     (-0.0845, 0.364]\n",
       "2832    (-0.533, -0.0845]\n",
       "2833     (-0.0845, 0.364]\n",
       "Name: target, Length: 2834, dtype: category\n",
       "Categories (12, interval[float64]): [(-3.682, -3.227] < (-3.227, -2.778] < (-2.778, -2.329] < (-2.329, -1.88] ... (-0.0845, 0.364] < (0.364, 0.813] < (0.813, 1.262] < (1.262, 1.711]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(train_data['target'],bins=num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ea6cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 55., 120., 280., 402., 490., 563., 458., 312., 123.,  31.]),\n",
       " array([-3.67626777, -3.13750201, -2.59873625, -2.05997049, -1.52120473,\n",
       "        -0.98243897, -0.44367321,  0.09509255,  0.63385831,  1.17262407,\n",
       "         1.71138983]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(target, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be747b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHcAAARuCAYAAABZdttIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuEklEQVR4nO3df+xld13n8debGcEiiGIRlgGp7rAoGlTSgJvdRF2JWxRtNLoBf2F0/ZEsszXRKATjrwU16/4QR6JgrBhlQV01oFZRk03YqKCtVgUB85VY2+FXoRbQVrDtZ/+Yb9mvte1M2/nO+b7m+3gkk9x77jn3vm84d7j3OeeczlorAAAAAHR60NYDAAAAAHD/iTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAtWbmr2fmGYfttQEA9hJ3AIBDaWaObD0DAMC5IO4AAJVm5ueSfFKSX5uZv5uZ75yZX5qZd83M+2fm9TPz6XvWf8XM/MTMXDUzf5/k82fmqTPzJzPzwd1tf2FmXrRnm2fNzLUzc/PM/P7MPOWeXvs8v30AgI8QdwCASmutr03yN0m+ZK31sLXWf03ym0memOQTk/xxklfeZbOvSvLiJA9P8odJfjXJK5I8MsmrknzZnSvOzFOTXJnkW5J8QpKXJXntzDzkHl4bAGAT4g4AcMFYa1251vrgWutDSb4vyWfOzCP2rPKatdbvrbXuSPJZSY4m+bG11j+utX4lp4PPnb4pycvWWm9ca92+1vrZJB9K8jnn5c0AAJwlcQcAuCDMzJGZ+eGZ+auZ+UCSv9596OI9q12/5/Zjk5xaa617ePwJSb5995Ssm2fm5iSP390OAODAEHcAgGZ7w8xXJbk8yTOSPCLJJbvL5x7Wf2eSYzOz9/HH77l9fZIXr7U+bs+fh661XnU3zwUAsBlxBwBo9u4kn7J7++E5fdrU+5I8NMkPnmHbP0hye5LnzczRmbk8ydP2PP5TSb51Zp4+p33MzHzxzDz8bl4bAGAz4g4A0OyHknz37ilTj0xyXZJTSf4iyRvubcO11oeTfHmSb0xyc5KvSfLrOR2Ista6Oqevu/PjSf42yU6Sr7+7156Z7zhXbwgA4L6af3qaOQDA4TUzb0zyk2utn9l6FgCAs+XIHQDg0JqZz52Zx+yelvXcJE9J8ltbzwUAcF8c3XoAAIANPSnJLyZ5WJK/SvIVa613bjsSAMB947QsAAAAgGJOywIAAAAoJu4AAAAAFNuXa+5cfPHF65JLLtmPpwYAAAA4lK655pr3rrUeddfl+xJ3Lrnkklx99dX78dQAAAAAh9LMXHd3y52WBQAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBiR7ceAADOh5MnT2ZnZ2frMbgAnDp1Kkly7NixjSfhIDl+/HhOnDix9RgAHFLiDgCHws7OTq5901ty+0MfufUolDtyy/uTJO/6kK9RnHbklpu2HgGAQ863EgAOjdsf+sjc+qlftPUYlLvorVcliX2Jj7hznwCArbjmDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLizj04efJkTp48ufUYAAAAwP10WH7bH916gINqZ2dn6xEAAACAB+Cw/LZ35A4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAip1V3JmZy2bmbTOzMzPP3++hAAAAADg7Z4w7M3MkyUuTPDPJk5M8Z2aevN+DAQAAAHBmZ3PkztOS7Ky13r7W+nCSVye5fH/HAgAAAOBsHD2LdY4luX7P/RuSPH1/xjk4Tp06lVtvvTVXXHHF1qMAcA7s7OzkQR9eW48BXIAe9A8fyM7OB31vBDiAdnZ2ctFFF209xr47myN35m6W/bNvxzPzzTNz9cxcfeONNz7wyQAAAAA4o7M5cueGJI/fc/9xSd5x15XWWi9P8vIkufTSS+v/afTYsWNJkpe85CUbTwLAuXDFFVfkmre/e+sxgAvQHR/9sTn+KY/2vRHgADosR1WezZE7f5TkiTPzyTPz4CTPTvLa/R0LAAAAgLNxxiN31lq3zczzkrwuyZEkV6613rzvkwEAAABwRmdzWlbWWlcluWqfZwEAAADgPjqb07IAAAAAOKDEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACh2dOsBDqrjx49vPQIAAADwAByW3/bizj04ceLE1iMAAAAAD8Bh+W3vtCwAAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIod3XoAADhfjtxyUy5661Vbj0G5I7e8L0nsS3zEkVtuSvLorccA4BATdwA4FI4fP771CFwgTp26LUly7Jgf89zp0f6OAWBT4g4Ah8KJEye2HgEAAPaFa+4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoNmutc/+kMzcmue6cPzGcXxcnee/WQ8B5Yn/nMLG/c9jY5zlM7O9c6J6w1nrUXRfuS9yBC8HMXL3WunTrOeB8sL9zmNjfOWzs8xwm9ncOK6dlAQAAABQTdwAAAACKiTtwz16+9QBwHtnfOUzs7xw29nkOE/s7h5Jr7gAAAAAUc+QOAAAAQDFxB+7BzPyXmfmzmbl2Zn57Zh679Uywn2bmR2bmrbv7/a/OzMdtPRPsl5n5ypl588zcMTP+qypckGbmspl528zszMzzt54H9tPMXDkz75mZN209C2xB3IF79iNrraestT4rya8n+Z6N54H99jtJPmOt9ZQkf5nkBRvPA/vpTUm+PMnrtx4E9sPMHEny0iTPTPLkJM+ZmSdvOxXsq1ckuWzrIWAr4g7cg7XWB/bc/ZgkLlDFBW2t9dtrrdt2774hyeO2nAf201rrLWutt209B+yjpyXZWWu9fa314SSvTnL5xjPBvllrvT7JTVvPAVs5uvUAcJDNzIuTfF2S9yf5/I3HgfPpG5L8wtZDAHC/HUty/Z77NyR5+kazALDPxB0OtZn53SSPuZuHXrjWes1a64VJXjgzL0jyvCTfe14HhHPsTPv87jovTHJbkleez9ngXDub/R0uYHM3yxyFDHCBEnc41NZazzjLVf9Xkt+IuEO5M+3zM/PcJM9K8gVrLT8CqHYf/o6HC9ENSR6/5/7jkrxjo1kA2GeuuQP3YGaeuOfulyZ561azwPkwM5cl+a4kX7rWumXreQB4QP4oyRNn5pNn5sFJnp3ktRvPBMA+Gf8wC3dvZn45yZOS3JHkuiTfutY6te1UsH9mZifJQ5K8b3fRG9Za37rhSLBvZubLkpxM8qgkNye5dq317zcdCs6xmfmiJD+a5EiSK9daL952Itg/M/OqJJ+X5OIk707yvWutn950KDiPxB0AAACAYk7LAgAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAfYzFwyM2tmjm49CwBwMIk7AMA5NTN/PTPPOGyvDQCwFXEHADgwZubI1jPcV46oAQC2Ju4AAOfMzPxckk9K8msz83cz850z80sz866Zef/MvH5mPn3P+q+YmZ+Ymatm5u+TfP7MPHVm/mRmPri77S/MzIv2bPOsmbl2Zm6emd+fmafc02vfy5x3nur03Jn5m5l578y8cM/jD5mZH52Zd+z++dGZecjuY583MzfMzHfNzLuS/MzMfN/urD+/O/efz8y/mpkXzMx7Zub6mfnCPc//iJn56Zl558ycmpkX3Rm2ZubIzPy33ZnenuSLz9H/PADABUrcAQDOmbXW1yb5myRfstZ62Frrvyb5zSRPTPKJSf44ySvvstlXJXlxkocn+cMkv5rkFUkemeRVSb7szhVn5qlJrkzyLUk+IcnLkrx2Zh5yD699Jv82yZOSfEGS75mZT9td/sIkn5Pks5J8ZpKnJfnuPds9Zne+JyT55t1lX5Lk55J8fJI/SfK6nP6udSzJD+zOeqefTXJbkuNJPjvJFyb5j7uPfVOSZ+0uvzTJV5zF+wAADjFxBwDYV2utK9daH1xrfSjJ9yX5zJl5xJ5VXrPW+r211h05HVOOJvmxtdY/rrV+JaeDz52+KcnL1lpvXGvdvtb62SQfyukQc398/1rr1rXWnyb505wOOUny1Ul+YK31nrXWjUm+P8nX7tnujiTfu9b60Frr1t1l/3et9bq11m1JfinJo5L88FrrH5O8OsklM/NxM/PoJM9M8m1rrb9fa70nyf9M8uzd5/kPSX50rXX9WuumJD90P98bAHBIOEccANg3u6cavTjJV+Z07Lhj96GLk7x/9/b1ezZ5bJJTa621Z9nex5+Q5Lkzc2LPsgfvbnd/vGvP7VuSPGzPHNfteey6u7zGjWutf7jLc717z+1bk7x3rXX7nvvZff7HJvmoJO+cmTvXf1D+//t8bP7pe947BwDAPyPuAADn2t4w81VJLk/yjCR/neQRSf42ydzD+u9McmxmZk/geXySv9q9fX2SF6+1XnwWr/1AvCOnQ9Kbd+9/0u6yc/E61+f00UYX7x7lc1fvzOn3fKdPegCvBQAcAk7LAgDOtXcn+ZTd2w/P6ZDxviQPTfKDZ9j2D5LcnuR5M3N0Zi7P6evd3OmnknzrzDx9TvuYmfnimXn43bz2A/GqJN89M4+amYuTfE+Snz8Hz5u11juT/HaS/z4zHzszD5qZfzkzn7u7yi8m+c8z87iZ+fgkzz8XrwsAXLjEHQDgXPuhnA4jN+f0RYevS3IqyV8kecO9bbjW+nCSL0/yjUluTvI1SX49pwNR1lpX5/R1d348p48A2kny9Xf32jPzHQ/gPbwoydVJ/izJn+f0haBfdK9b3Ddfl9Onk/1FTr+P/53kX+w+9lM5fTHmP9193V85h68LAFyA5p+e0g4AcLDMzBuT/ORa62e2ngUA4CBy5A4AcKDMzOfOzGN2T8t6bpKnJPmtrecCADioxB0A4KB5Uk6fkvT+JN+e5Ct2r1Nzn8zMV8/M393NnzefeWsAgB5OywIAAAAo5sgdAAAAgGLiDgAAAECxo/vxpBdffPG65JJL9uOpAQAAAA6la6655r1rrUfddfm+xJ1LLrkkV1999X48NQAAAMChNDPX3d1yp2UBAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoNjRrQcAgPPh5MmT2dnZ2XoMLgCnTp1Kkhw7dmzjSThIjh8/nhMnTmw9BgCHlLgDwKGws7OTa9/0ltz+0EduPQrljtzy/iTJuz7kaxSnHbnlpq1HAOCQ860EgEPj9oc+Mrd+6hdtPQblLnrrVUliX+Ij7twnAGArrrkDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLhzD06ePJmTJ09uPQYAAABwPx2W3/ZHtx7goNrZ2dl6BAAAAOABOCy/7R25AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBiZxV3ZuaymXnbzOzMzPP3eygAAAAAzs4Z487MHEny0iTPTPLkJM+ZmSfv92AAAAAAnNnZHLnztCQ7a623r7U+nOTVSS7f37EAAAAAOBtHz2KdY0mu33P/hiRP359xDo5Tp07l1ltvzRVXXLH1KACcAzs7O3nQh9fWYwAXoAf9wweys/NB3xsBDqCdnZ1cdNFFW4+x787myJ25m2X/7NvxzHzzzFw9M1ffeOOND3wyAAAAAM7obI7cuSHJ4/fcf1ySd9x1pbXWy5O8PEkuvfTS+n8aPXbsWJLkJS95ycaTAHAuXHHFFbnm7e/eegzgAnTHR39sjn/Ko31vBDiADstRlWdz5M4fJXnizHzyzDw4ybOTvHZ/xwIAAADgbJzxyJ211m0z87wkr0tyJMmVa6037/tkAAAAAJzR2ZyWlbXWVUmu2udZAAAAALiPzua0LAAAAAAOKHEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAih3deoCD6vjx41uPAAAAADwAh+W3vbhzD06cOLH1CAAAAMADcFh+2zstCwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYke3HgAAzpcjt9yUi9561dZjUO7ILe9LEvsSH3HklpuSPHrrMQA4xMQdAA6F48ePbz0CF4hTp25Lkhw75sc8d3q0v2MA2JS4A8ChcOLEia1HAACAfeGaOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIqJOwAAAADFxB0AAACAYuIOAAAAQDFxBwAAAKCYuAMAAABQTNwBAAAAKCbuAAAAABQTdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAUE3cAAAAAiok7AAAAAMXEHQAAAIBi4g4AAABAMXEHAAAAoJi4AwAAAFBM3AEAAAAoJu4AAAAAFBN3AAAAAIrNWuvcP+nMjUmuO+dPDGfn4iTv3XoIOMB8RuDe+YzAvfMZgXvnM8J+esJa61F3XbgvcQe2NDNXr7Uu3XoOOKh8RuDe+YzAvfMZgXvnM8IWnJYFAAAAUEzcAQAAACgm7nAhevnWA8AB5zMC985nBO6dzwjcO58RzjvX3AEAAAAo5sgdAAAAgGLiDhecmfmRmXnrzPzZzPzqzHzc1jPBQTMzXzkzb56ZO2bGf80BkszMZTPztpnZmZnnbz0PHDQzc+XMvGdm3rT1LHAQzczjZ+b/zMxbdr9nXbH1TBwe4g4Xot9J8hlrrack+cskL9h4HjiI3pTky5O8futB4CCYmSNJXprkmUmenOQ5M/PkbaeCA+cVSS7begg4wG5L8u1rrU9L8jlJ/pP/L+F8EXe44Ky1fnutddvu3TckedyW88BBtNZ6y1rrbVvPAQfI05LsrLXevtb6cJJXJ7l845ngQFlrvT7JTVvPAQfVWuuda60/3r39wSRvSXJs26k4LMQdLnTfkOQ3tx4CgAPvWJLr99y/Ib6QA3A/zcwlST47yRs3HoVD4ujWA8D9MTO/m+Qxd/PQC9dar9ld54U5fWjkK8/nbHBQnM3nBPiIuZtl/pOiANxnM/OwJL+c5NvWWh/Yeh4OB3GHSmutZ9zb4zPz3CTPSvIFay1fzjmUzvQ5Af6JG5I8fs/9xyV5x0azAFBqZj4qp8POK9dav7L1PBweTsvigjMzlyX5riRfuta6Zet5AKjwR0meODOfPDMPTvLsJK/deCYAiszMJPnpJG9Za/2PrefhcBF3uBD9eJKHJ/mdmbl2Zn5y64HgoJmZL5uZG5L86yS/MTOv23om2NLuhfifl+R1OX0BzF9ca71526ngYJmZVyX5gyRPmpkbZuYbt54JDph/k+Rrk/y73d8h187MF209FIfDOGMFAAAAoJcjdwAAAACKiTsAAAAAxcQdAAAAgGLiDgAAAEAxcQcAAACgmLgDAAAAUEzcAQAAACgm7gAAAAAU+39iF7deaQ2KxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 20))\n",
    "for i, (data, data_name) in enumerate(zip([target, target_normed], ['target', 'target_normed'])):\n",
    "    sns.boxplot(data=data, orient='h', ax = ax[i])\n",
    "    ax[i].set_title(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7260308d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.646900</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2c26db523</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>So what is a solid? Solids are usually hard be...</td>\n",
       "      <td>0.189476</td>\n",
       "      <td>0.535648</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>cd19e2350</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>The second state of matter we will discuss is ...</td>\n",
       "      <td>0.255209</td>\n",
       "      <td>0.483866</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>15e2e9e7a</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Solids are shapes that you can actually touch....</td>\n",
       "      <td>-0.215279</td>\n",
       "      <td>0.514128</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>5b990ba77</td>\n",
       "      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Animals are made of many cells. They eat thing...</td>\n",
       "      <td>0.300779</td>\n",
       "      <td>0.512379</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2834 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          url_legal  \\\n",
       "0     c12129c31                                                NaN   \n",
       "1     85aa80a4c                                                NaN   \n",
       "2     b69ac6792                                                NaN   \n",
       "3     dd1000b26                                                NaN   \n",
       "4     37c1b32fb                                                NaN   \n",
       "...         ...                                                ...   \n",
       "2829  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n",
       "2830  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2831  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n",
       "2832  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n",
       "2833  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n",
       "\n",
       "           license                                            excerpt  \\\n",
       "0              NaN  When the young people returned to the ballroom...   \n",
       "1              NaN  All through dinner time, Mrs. Fayre was somewh...   \n",
       "2              NaN  As Roger had predicted, the snow departed as q...   \n",
       "3              NaN  And outside before the palace a great garden w...   \n",
       "4              NaN  Once upon a time there were Three Bears who li...   \n",
       "...            ...                                                ...   \n",
       "2829  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n",
       "2830  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n",
       "2831  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n",
       "2832  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n",
       "2833  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n",
       "\n",
       "        target  standard_error  bins  \n",
       "0    -0.340259        0.464009     7  \n",
       "1    -0.315372        0.480805     7  \n",
       "2    -0.580118        0.476676     6  \n",
       "3    -1.054013        0.450007     5  \n",
       "4     0.247197        0.510845     8  \n",
       "...        ...             ...   ...  \n",
       "2829  1.711390        0.646900    11  \n",
       "2830  0.189476        0.535648     8  \n",
       "2831  0.255209        0.483866     8  \n",
       "2832 -0.215279        0.514128     7  \n",
       "2833  0.300779        0.512379     8  \n",
       "\n",
       "[2834 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ad4482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My hope lay in Jack's promise that he would ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dotty continued to go to Mrs. Gray's every nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It was a bright and cheerful scene that greete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cell_division</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Cell division is the process by which a parent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Debugging</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Debugging is the process of finding and resolv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12537fe78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To explain transitivity, let us look first at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965e592c0</td>\n",
       "      <td>https://www.africanstorybook.org/#</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>Milka and John are playing in the garden. Her ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                    url_legal       license  \\\n",
       "0  c0f722661                                          NaN           NaN   \n",
       "1  f0953f0a5                                          NaN           NaN   \n",
       "2  0df072751                                          NaN           NaN   \n",
       "3  04caf4e0c  https://en.wikipedia.org/wiki/Cell_division  CC BY-SA 3.0   \n",
       "4  0e63f8bea      https://en.wikipedia.org/wiki/Debugging  CC BY-SA 3.0   \n",
       "5  12537fe78                                          NaN           NaN   \n",
       "6  965e592c0           https://www.africanstorybook.org/#     CC BY 4.0   \n",
       "\n",
       "                                             excerpt  \n",
       "0  My hope lay in Jack's promise that he would ke...  \n",
       "1  Dotty continued to go to Mrs. Gray's every nig...  \n",
       "2  It was a bright and cheerful scene that greete...  \n",
       "3  Cell division is the process by which a parent...  \n",
       "4  Debugging is the process of finding and resolv...  \n",
       "5  To explain transitivity, let us look first at ...  \n",
       "6  Milka and John are playing in the garden. Her ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ce9e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>25ca8f498</td>\n",
       "      <td>When you think of dinosaurs and where they liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2c26db523</td>\n",
       "      <td>So what is a solid? Solids are usually hard be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>cd19e2350</td>\n",
       "      <td>The second state of matter we will discuss is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>15e2e9e7a</td>\n",
       "      <td>Solids are shapes that you can actually touch....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>5b990ba77</td>\n",
       "      <td>Animals are made of many cells. They eat thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2834 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            excerpt\n",
       "0     c12129c31  When the young people returned to the ballroom...\n",
       "1     85aa80a4c  All through dinner time, Mrs. Fayre was somewh...\n",
       "2     b69ac6792  As Roger had predicted, the snow departed as q...\n",
       "3     dd1000b26  And outside before the palace a great garden w...\n",
       "4     37c1b32fb  Once upon a time there were Three Bears who li...\n",
       "...         ...                                                ...\n",
       "2829  25ca8f498  When you think of dinosaurs and where they liv...\n",
       "2830  2c26db523  So what is a solid? Solids are usually hard be...\n",
       "2831  cd19e2350  The second state of matter we will discuss is ...\n",
       "2832  15e2e9e7a  Solids are shapes that you can actually touch....\n",
       "2833  5b990ba77  Animals are made of many cells. They eat thing...\n",
       "\n",
       "[2834 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.drop(['target', 'url_legal', 'license', 'standard_error', 'bins'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c83d8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data.drop(['target', 'url_legal', 'license', 'standard_error', 'bins'], 1),\n",
    "    target_normed, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3012e17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>a16f5d2c6</td>\n",
       "      <td>Tom and his crowd looked down the path and saw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>14112c6ee</td>\n",
       "      <td>The Miranda warning, which can also be referre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>9635671b4</td>\n",
       "      <td>They have kangaroo rats, and dogs of the jacka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>b5944cff3</td>\n",
       "      <td>No boy can afford to neglect his work, and, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>5cd839366</td>\n",
       "      <td>We know these motor representations are stored...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>240b89006</td>\n",
       "      <td>The steam is supplied by two circular return t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>243f9f286</td>\n",
       "      <td>Living things are different from things that a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>e044e1347</td>\n",
       "      <td>I'd always longed for adventures. You see, my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>7d016018e</td>\n",
       "      <td>In these times one dread lies heavy on heart a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1c6ffcd35</td>\n",
       "      <td>Dog is in his house. Dog is sitting in his hou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1898 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            excerpt\n",
       "2383  a16f5d2c6  Tom and his crowd looked down the path and saw...\n",
       "489   14112c6ee  The Miranda warning, which can also be referre...\n",
       "2227  9635671b4  They have kangaroo rats, and dogs of the jacka...\n",
       "1417  b5944cff3  No boy can afford to neglect his work, and, wi...\n",
       "690   5cd839366  We know these motor representations are stored...\n",
       "...         ...                                                ...\n",
       "1638  240b89006  The steam is supplied by two circular return t...\n",
       "1095  243f9f286  Living things are different from things that a...\n",
       "1130  e044e1347  I'd always longed for adventures. You see, my ...\n",
       "1294  7d016018e  In these times one dread lies heavy on heart a...\n",
       "860   1c6ffcd35  Dog is in his house. Dog is sitting in his hou...\n",
       "\n",
       "[1898 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d23974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, target, tokenizer):\n",
    "        super(Dataset).__init__()\n",
    "        self.data = [(row[1]['id'], row[1]['excerpt']) for row in data.iterrows()]\n",
    "        self.target = target\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encode = self.tokenizer(self.data[idx][1],return_tensors='pt',\n",
    "                                max_length=config['max_len'],\n",
    "                                padding='max_length',truncation=True)\n",
    "        return self.data[idx][0], encode, self.target\n",
    "#         return data[idx]['id'], data[idx]['excerpt'], target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28a3d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train, tokenizer)\n",
    "test_dataset = CustomDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c7781",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "overall-newton",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:28:28.733073Z",
     "iopub.status.busy": "2021-06-09T10:28:28.732488Z",
     "iopub.status.idle": "2021-06-09T10:28:28.738246Z",
     "shell.execute_reply": "2021-06-09T10:28:28.737845Z",
     "shell.execute_reply.started": "2021-06-09T10:10:09.775834Z"
    },
    "papermill": {
     "duration": 0.02788,
     "end_time": "2021-06-09T10:28:28.738355",
     "exception": false,
     "start_time": "2021-06-09T10:28:28.710475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'batch_size':128,\n",
    "    'max_len':256,\n",
    "    'nfolds':5,\n",
    "    'seed':42,\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed=config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "funny-folder",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:28:28.777312Z",
     "iopub.status.busy": "2021-06-09T10:28:28.776556Z",
     "iopub.status.idle": "2021-06-09T10:28:28.779147Z",
     "shell.execute_reply": "2021-06-09T10:28:28.778749Z",
     "shell.execute_reply.started": "2021-06-09T10:10:12.967009Z"
    },
    "papermill": {
     "duration": 0.024271,
     "end_time": "2021-06-09T10:28:28.779255",
     "exception": false,
     "start_time": "2021-06-09T10:28:28.754984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CLRPDataset(Dataset):\n",
    "    def __init__(self,df,tokenizer):\n",
    "        self.excerpt = df['excerpt'].to_numpy()\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n",
    "                                max_length=config['max_len'],\n",
    "                                padding='max_length',truncation=True)\n",
    "        return encode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "listed-poland",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:28:28.818800Z",
     "iopub.status.busy": "2021-06-09T10:28:28.818103Z",
     "iopub.status.idle": "2021-06-09T10:28:28.820412Z",
     "shell.execute_reply": "2021-06-09T10:28:28.820822Z",
     "shell.execute_reply.started": "2021-06-09T10:10:16.466192Z"
    },
    "papermill": {
     "duration": 0.024949,
     "end_time": "2021-06-09T10:28:28.820940",
     "exception": false,
     "start_time": "2021-06-09T10:28:28.795991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, num_targets):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.middle_features = hidden_dim\n",
    "\n",
    "        self.W = nn.Linear(in_features, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "        self.out_features = hidden_dim\n",
    "\n",
    "    def forward(self, features):\n",
    "        att = torch.tanh(self.W(features))\n",
    "\n",
    "        score = self.V(att)\n",
    "\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "spectacular-prison",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:28:28.860421Z",
     "iopub.status.busy": "2021-06-09T10:28:28.859674Z",
     "iopub.status.idle": "2021-06-09T10:28:28.862246Z",
     "shell.execute_reply": "2021-06-09T10:28:28.861862Z",
     "shell.execute_reply.started": "2021-06-09T10:10:34.505708Z"
    },
    "papermill": {
     "duration": 0.02484,
     "end_time": "2021-06-09T10:28:28.862352",
     "exception": false,
     "start_time": "2021-06-09T10:28:28.837512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base') \n",
    "        self.head = AttentionHead(768,768,1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(self.head.out_features,1)\n",
    "\n",
    "    def forward(self,**xb):\n",
    "        x = self.roberta(**xb)[0]\n",
    "        x = self.head(x)\n",
    "        x = self.droput(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "83c738bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "epochs = 1\n",
    "\n",
    "def train(\n",
    "    model, opt, loss_fn,\n",
    "    train_loader, test_loader,\n",
    "    epochs\n",
    "):\n",
    "    for epoch in range(epochs):\n",
    "        for ids, X_batch, y_batch in train_loader:\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            y_batch = torch.Tensor(y_batch.float())\n",
    "            \n",
    "            inputs = {key:val.reshape(val.shape[0],-1) for key,val in X_batch.items()}\n",
    "            print (inputs)\n",
    "            y_pred = model.forward(**inputs)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            \n",
    "            loss.baskward()\n",
    "            opt.step()\n",
    "        \n",
    "        for ids, X_batch, y_batch in test_loader:\n",
    "\n",
    "            y_batch = torch.Tensor(y_batch.float())\n",
    "            \n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            \n",
    "            print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7693ea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0, 15691,     8,  ...,     1,     1,     1],\n",
      "        [    0,   133, 16002,  ...,     1,     1,     1],\n",
      "        [    0,  1213,    33,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,   133, 24883,  ...,     1,     1,     1],\n",
      "        [    0,   100,   109,  ...,     1,     1,     1],\n",
      "        [    0,  1185,   189,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-a8f32b127180>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train(model, optimizer, loss_fn,\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     epochs)\n",
      "\u001b[1;32m<ipython-input-175-fd8415c16561>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, opt, loss_fn, train_loader, test_loader, epochs)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-144-18b341483e6d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, **xb)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroberta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\transformers-4.6.1-py3.8.egg\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    813\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         )\n\u001b[1;32m--> 815\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    816\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\transformers-4.6.1-py3.8.egg\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    506\u001b[0m                 )\n\u001b[0;32m    507\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    509\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\transformers-4.6.1-py3.8.egg\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         )\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\transformers-4.6.1-py3.8.egg\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m   1993\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1995\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\transformers-4.6.1-py3.8.egg\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\transformers-4.6.1-py3.8.egg\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, optimizer, loss_fn,\n",
    "    train_loader, test_loader,\n",
    "    epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a940b7e",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "billion-medicine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:28:28.903739Z",
     "iopub.status.busy": "2021-06-09T10:28:28.903072Z",
     "iopub.status.idle": "2021-06-09T10:28:28.905741Z",
     "shell.execute_reply": "2021-06-09T10:28:28.905323Z",
     "shell.execute_reply.started": "2021-06-09T10:10:37.319896Z"
    },
    "papermill": {
     "duration": 0.026744,
     "end_time": "2021-06-09T10:28:28.905847",
     "exception": false,
     "start_time": "2021-06-09T10:28:28.879103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embeddings(df,path,plot_losses=True, verbose=True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"{device} is used\")\n",
    "            \n",
    "    model = Model()\n",
    "#     model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    print ('asd')\n",
    "    ds = CLRPDataset(df,tokenizer)\n",
    "    dl = DataLoader(ds,\n",
    "                  batch_size = config[\"batch_size\"],\n",
    "                  shuffle=False,\n",
    "                  num_workers = 4,\n",
    "                  pin_memory=True,\n",
    "                  drop_last=False\n",
    "                 )\n",
    "        \n",
    "    embeddings = list()\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in tqdm(enumerate(dl)):\n",
    "            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            embeddings.extend(outputs)\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0a491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "train_embeddings1 =  get_embeddings(train_data,'../input/clr-roberta/model0/model0.bin')\n",
    "test_embeddings1 = get_embeddings(test_data,'../input/clr-roberta/model0/model0.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-drunk",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:28:28.992974Z",
     "iopub.status.busy": "2021-06-09T10:28:28.992455Z",
     "iopub.status.idle": "2021-06-09T10:31:34.936265Z",
     "shell.execute_reply": "2021-06-09T10:31:34.936691Z",
     "shell.execute_reply.started": "2021-06-09T10:10:40.283404Z"
    },
    "papermill": {
     "duration": 186.014241,
     "end_time": "2021-06-09T10:31:34.936855",
     "exception": false,
     "start_time": "2021-06-09T10:28:28.922614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "train_embeddings1 =  get_embeddings(train_data,'../input/clr-roberta/model0/model0.bin')\n",
    "test_embeddings1 = get_embeddings(test_data,'../input/clr-roberta/model0/model0.bin')\n",
    "\n",
    "train_embeddings2 =  get_embeddings(train_data,'../input/clr-roberta/model1/model1.bin')\n",
    "test_embeddings2 = get_embeddings(test_data,'../input/clr-roberta/model1/model1.bin')\n",
    "\n",
    "train_embeddings3 =  get_embeddings(train_data,'../input/clr-roberta/model2/model2.bin')\n",
    "test_embeddings3 = get_embeddings(test_data,'../input/clr-roberta/model2/model2.bin')\n",
    "\n",
    "train_embeddings4 =  get_embeddings(train_data,'../input/clr-roberta/model3/model3.bin')\n",
    "test_embeddings4 = get_embeddings(test_data,'../input/clr-roberta/model3/model3.bin')\n",
    "\n",
    "train_embeddings5 =  get_embeddings(train_data,'../input/clr-roberta/model4/model4.bin')\n",
    "test_embeddings5 = get_embeddings(test_data,'../input/clr-roberta/model4/model4.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-athens",
   "metadata": {
    "papermill": {
     "duration": 0.054636,
     "end_time": "2021-06-09T10:31:35.047229",
     "exception": false,
     "start_time": "2021-06-09T10:31:34.992593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "macro-madagascar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:31:35.165727Z",
     "iopub.status.busy": "2021-06-09T10:31:35.165064Z",
     "iopub.status.idle": "2021-06-09T10:31:35.168868Z",
     "shell.execute_reply": "2021-06-09T10:31:35.168452Z",
     "shell.execute_reply.started": "2021-06-09T10:15:51.394572Z"
    },
    "papermill": {
     "duration": 0.067091,
     "end_time": "2021-06-09T10:31:35.168973",
     "exception": false,
     "start_time": "2021-06-09T10:31:35.101882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preds_svm(X,y,X_test,bins=bins,nfolds=5,C=10,kernel='rbf'):\n",
    "    scores = list()\n",
    "    preds = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n",
    "    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n",
    "        model = SVR(C=C,kernel=kernel,gamma='auto')\n",
    "        X_train,y_train = X[train_idx], y[train_idx]\n",
    "        X_valid,y_valid = X[valid_idx], y[valid_idx]\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        prediction = model.predict(X_valid)\n",
    "        score = rmse_score(prediction,y_valid)\n",
    "        print(f'Fold {k} , rmse score: {score}')\n",
    "        scores.append(score)\n",
    "        preds += model.predict(X_test)\n",
    "        \n",
    "    print(\"mean rmse\",np.mean(scores))\n",
    "    return np.array(preds)/nfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "concrete-cowboy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:31:35.284329Z",
     "iopub.status.busy": "2021-06-09T10:31:35.283822Z",
     "iopub.status.idle": "2021-06-09T10:32:16.875382Z",
     "shell.execute_reply": "2021-06-09T10:32:16.876210Z",
     "shell.execute_reply.started": "2021-06-09T10:15:54.670832Z"
    },
    "papermill": {
     "duration": 41.6524,
     "end_time": "2021-06-09T10:32:16.876436",
     "exception": false,
     "start_time": "2021-06-09T10:31:35.224036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 , rmse score: 0.47727497027807975\n",
      "Fold 1 , rmse score: 0.2578880377682382\n",
      "Fold 2 , rmse score: 0.2541082644861084\n",
      "Fold 3 , rmse score: 0.24054325983483563\n",
      "Fold 4 , rmse score: 0.2551938404392728\n",
      "mean rmse 0.297001674561307\n",
      "Fold 0 , rmse score: 0.2425235616562364\n",
      "Fold 1 , rmse score: 0.5016510069411838\n",
      "Fold 2 , rmse score: 0.23847703706225037\n",
      "Fold 3 , rmse score: 0.23492862892763802\n",
      "Fold 4 , rmse score: 0.24930508381707772\n",
      "mean rmse 0.2933770636808773\n",
      "Fold 0 , rmse score: 0.3908661185328736\n",
      "Fold 1 , rmse score: 0.4135395361379846\n",
      "Fold 2 , rmse score: 0.4895740066653232\n",
      "Fold 3 , rmse score: 0.3756053322147557\n",
      "Fold 4 , rmse score: 0.4008420352519307\n",
      "mean rmse 0.4140854057605735\n",
      "Fold 0 , rmse score: 0.2878583154409844\n",
      "Fold 1 , rmse score: 0.27540087825175247\n",
      "Fold 2 , rmse score: 0.2809937810667762\n",
      "Fold 3 , rmse score: 0.45763179894261946\n",
      "Fold 4 , rmse score: 0.2852643347020617\n",
      "mean rmse 0.31742982168083883\n",
      "Fold 0 , rmse score: 0.4013671778501825\n",
      "Fold 1 , rmse score: 0.4266264148954528\n",
      "Fold 2 , rmse score: 0.4028700034689983\n",
      "Fold 3 , rmse score: 0.3969900356101473\n",
      "Fold 4 , rmse score: 0.5105196639952477\n",
      "mean rmse 0.4276746591640057\n"
     ]
    }
   ],
   "source": [
    "svm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1)\n",
    "svm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2)\n",
    "svm_preds3 = get_preds_svm(train_embeddings3,target,test_embeddings3)\n",
    "svm_preds4 = get_preds_svm(train_embeddings4,target,test_embeddings4)\n",
    "svm_preds5 = get_preds_svm(train_embeddings5,target,test_embeddings5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "executive-penny",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:32:17.004080Z",
     "iopub.status.busy": "2021-06-09T10:32:17.003571Z",
     "iopub.status.idle": "2021-06-09T10:32:17.007449Z",
     "shell.execute_reply": "2021-06-09T10:32:17.007040Z",
     "shell.execute_reply.started": "2021-06-09T10:16:39.410482Z"
    },
    "papermill": {
     "duration": 0.068464,
     "end_time": "2021-06-09T10:32:17.007559",
     "exception": false,
     "start_time": "2021-06-09T10:32:16.939095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-mother",
   "metadata": {
    "papermill": {
     "duration": 0.061081,
     "end_time": "2021-06-09T10:32:17.129456",
     "exception": false,
     "start_time": "2021-06-09T10:32:17.068375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The second notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "joined-removal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:32:17.267846Z",
     "iopub.status.busy": "2021-06-09T10:32:17.266192Z",
     "iopub.status.idle": "2021-06-09T10:32:17.270224Z",
     "shell.execute_reply": "2021-06-09T10:32:17.269830Z",
     "shell.execute_reply.started": "2021-06-09T10:16:42.286661Z"
    },
    "papermill": {
     "duration": 0.079474,
     "end_time": "2021-06-09T10:32:17.270334",
     "exception": false,
     "start_time": "2021-06-09T10:32:17.190860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "standard-tyler",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:32:17.398649Z",
     "iopub.status.busy": "2021-06-09T10:32:17.398101Z",
     "iopub.status.idle": "2021-06-09T10:32:22.093060Z",
     "shell.execute_reply": "2021-06-09T10:32:22.092119Z",
     "shell.execute_reply.started": "2021-06-09T10:16:44.806836Z"
    },
    "papermill": {
     "duration": 4.761838,
     "end_time": "2021-06-09T10:32:22.093203",
     "exception": false,
     "start_time": "2021-06-09T10:32:17.331365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import (\n",
    "    Dataset, DataLoader, \n",
    "    SequentialSampler, RandomSampler\n",
    ")\n",
    "from transformers import RobertaConfig\n",
    "from transformers import (\n",
    "    get_cosine_schedule_with_warmup, \n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup\n",
    ")\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaModel\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "external-struggle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:32:22.225524Z",
     "iopub.status.busy": "2021-06-09T10:32:22.224713Z",
     "iopub.status.idle": "2021-06-09T10:32:22.226735Z",
     "shell.execute_reply": "2021-06-09T10:32:22.227220Z",
     "shell.execute_reply.started": "2021-06-09T10:16:49.504203Z"
    },
    "papermill": {
     "duration": 0.072015,
     "end_time": "2021-06-09T10:32:22.227345",
     "exception": false,
     "start_time": "2021-06-09T10:32:22.155330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
    "    data = data.replace('\\n', '')\n",
    "    tok = tokenizer.encode_plus(\n",
    "        data, \n",
    "        max_length=max_len, \n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    curr_sent = {}\n",
    "    padding_length = max_len - len(tok['input_ids'])\n",
    "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
    "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
    "        ([0] * padding_length)\n",
    "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
    "        ([0] * padding_length)\n",
    "    return curr_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unlike-dress",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:32:22.358820Z",
     "iopub.status.busy": "2021-06-09T10:32:22.358031Z",
     "iopub.status.idle": "2021-06-09T10:32:22.360727Z",
     "shell.execute_reply": "2021-06-09T10:32:22.360296Z",
     "shell.execute_reply.started": "2021-06-09T10:16:50.637933Z"
    },
    "papermill": {
     "duration": 0.07264,
     "end_time": "2021-06-09T10:32:22.360838",
     "exception": false,
     "start_time": "2021-06-09T10:32:22.288198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
    "        self.data = data\n",
    "        self.excerpts = self.data.excerpt.values.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if not self.is_test:\n",
    "            excerpt, label = self.excerpts[item], self.targets[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "                'label':torch.tensor(label, dtype=torch.double),\n",
    "            }\n",
    "        else:\n",
    "            excerpt = self.excerpts[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "global-secretary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:32:22.495352Z",
     "iopub.status.busy": "2021-06-09T10:32:22.494640Z",
     "iopub.status.idle": "2021-06-09T10:32:22.497416Z",
     "shell.execute_reply": "2021-06-09T10:32:22.497013Z",
     "shell.execute_reply.started": "2021-06-09T10:16:54.583861Z"
    },
    "papermill": {
     "duration": 0.076007,
     "end_time": "2021-06-09T10:32:22.497525",
     "exception": false,
     "start_time": "2021-06-09T10:32:22.421518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CommonLitModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name, \n",
    "        config,  \n",
    "        multisample_dropout=False,\n",
    "        output_hidden_states=False\n",
    "    ):\n",
    "        super(CommonLitModel, self).__init__()\n",
    "        self.config = config\n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            model_name, \n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "        if multisample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(0.5) for _ in range(5)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n",
    "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "        self._init_weights(self.layer_norm)\n",
    "        self._init_weights(self.regressor)\n",
    " \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    " \n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        sequence_output = outputs[1]\n",
    "        sequence_output = self.layer_norm(sequence_output)\n",
    " \n",
    "        # multi-sample dropout\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                logits = self.regressor(dropout(sequence_output))\n",
    "            else:\n",
    "                logits += self.regressor(dropout(sequence_output))\n",
    "        \n",
    "        logits /= len(self.dropouts)\n",
    " \n",
    "        # calculate loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
    "        \n",
    "        output = (logits,) + outputs[1:]\n",
    "        return ((loss,) + output) if loss is not None else output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qualified-timber",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:32:22.625586Z",
     "iopub.status.busy": "2021-06-09T10:32:22.624790Z",
     "iopub.status.idle": "2021-06-09T10:32:22.626947Z",
     "shell.execute_reply": "2021-06-09T10:32:22.627319Z",
     "shell.execute_reply.started": "2021-06-09T10:16:59.287637Z"
    },
    "papermill": {
     "duration": 0.069102,
     "end_time": "2021-06-09T10:32:22.627476",
     "exception": false,
     "start_time": "2021-06-09T10:32:22.558374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model(model_name, num_labels=1):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    config = RobertaConfig.from_pretrained(model_name)\n",
    "    config.update({'num_labels':num_labels})\n",
    "    model = CommonLitModel(model_name, config=config)\n",
    "    return model, tokenizer\n",
    "\n",
    "def make_loader(\n",
    "    data, \n",
    "    tokenizer, \n",
    "    max_len,\n",
    "    batch_size,\n",
    "):\n",
    "    \n",
    "    test_dataset = DatasetRetriever(data, tokenizer, max_len, is_test=True)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size // 2, \n",
    "        sampler=test_sampler, \n",
    "        pin_memory=False, \n",
    "        drop_last=False, \n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "monthly-authority",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:32:22.769788Z",
     "iopub.status.busy": "2021-06-09T10:32:22.768936Z",
     "iopub.status.idle": "2021-06-09T10:32:22.771918Z",
     "shell.execute_reply": "2021-06-09T10:32:22.771509Z",
     "shell.execute_reply.started": "2021-06-09T10:17:02.460230Z"
    },
    "papermill": {
     "duration": 0.073475,
     "end_time": "2021-06-09T10:32:22.772031",
     "exception": false,
     "start_time": "2021-06-09T10:32:22.698556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model, scalar=None):\n",
    "        self.model = model\n",
    "        self.scalar = scalar\n",
    "\n",
    "    def evaluate(self, data_loader, tokenizer):\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_data in enumerate(data_loader):\n",
    "                input_ids, attention_mask, token_type_ids = batch_data['input_ids'], \\\n",
    "                    batch_data['attention_mask'], batch_data['token_type_ids']\n",
    "                input_ids, attention_mask, token_type_ids = input_ids.cuda(), \\\n",
    "                    attention_mask.cuda(), token_type_ids.cuda()\n",
    "                \n",
    "                if self.scalar is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = self.model(\n",
    "                            input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                        )\n",
    "                else:\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids\n",
    "                    )\n",
    "                \n",
    "                logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n",
    "                preds += logits\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "limiting-alaska",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:32:22.902661Z",
     "iopub.status.busy": "2021-06-09T10:32:22.901850Z",
     "iopub.status.idle": "2021-06-09T10:32:22.904301Z",
     "shell.execute_reply": "2021-06-09T10:32:22.903919Z",
     "shell.execute_reply.started": "2021-06-09T10:17:04.788356Z"
    },
    "papermill": {
     "duration": 0.070248,
     "end_time": "2021-06-09T10:32:22.904426",
     "exception": false,
     "start_time": "2021-06-09T10:32:22.834178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def config(fold, model_name, load_model_path):\n",
    "    torch.manual_seed(2021)\n",
    "    torch.cuda.manual_seed(2021)\n",
    "    torch.cuda.manual_seed_all(2021)\n",
    "    \n",
    "    max_len = 250\n",
    "    batch_size = 8\n",
    "\n",
    "    model, tokenizer = make_model(\n",
    "        model_name=model_name, \n",
    "        num_labels=1\n",
    "    )\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'{load_model_path}/model{fold}.bin')\n",
    "    )\n",
    "    test_loader = make_loader(\n",
    "        test, tokenizer, max_len=max_len,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
    "            torch.cuda.device_count(), \n",
    "            torch.cuda.get_device_name(0))\n",
    "        )\n",
    "        model = model.cuda() \n",
    "    else:\n",
    "        raise ValueError('CPU training is not supported')\n",
    "\n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    scaler = None\n",
    "    return (\n",
    "        model, tokenizer, \n",
    "        test_loader, scaler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "federal-dance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:32:23.032536Z",
     "iopub.status.busy": "2021-06-09T10:32:23.031797Z",
     "iopub.status.idle": "2021-06-09T10:32:23.034447Z",
     "shell.execute_reply": "2021-06-09T10:32:23.034044Z",
     "shell.execute_reply.started": "2021-06-09T10:17:14.280693Z"
    },
    "papermill": {
     "duration": 0.069379,
     "end_time": "2021-06-09T10:32:23.034564",
     "exception": false,
     "start_time": "2021-06-09T10:32:22.965185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(fold=0, model_name=None, load_model_path=None):\n",
    "    model, tokenizer, \\\n",
    "        test_loader, scaler = config(fold, model_name, load_model_path)\n",
    "    \n",
    "    import time\n",
    "\n",
    "    evaluator = Evaluator(model, scaler)\n",
    "\n",
    "    test_time_list = []\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic1 = time.time()\n",
    "\n",
    "    preds = evaluator.evaluate(test_loader, tokenizer)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic2 = time.time() \n",
    "    test_time_list.append(tic2 - tic1)\n",
    "    \n",
    "    del model, tokenizer, test_loader, scaler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "jewish-elder",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:32:23.163416Z",
     "iopub.status.busy": "2021-06-09T10:32:23.162696Z",
     "iopub.status.idle": "2021-06-09T10:36:50.741895Z",
     "shell.execute_reply": "2021-06-09T10:36:50.742677Z",
     "shell.execute_reply.started": "2021-06-09T10:18:16.173971Z"
    },
    "papermill": {
     "duration": 267.647724,
     "end_time": "2021-06-09T10:36:50.742890",
     "exception": false,
     "start_time": "2021-06-09T10:32:23.095166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:05<04:22, 65.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:56<02:50, 56.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:46<01:47, 53.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:37<00:52, 52.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:27<00:00, 53.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 17.6 s, total: 1min 48s\n",
      "Wall time: 4min 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "\n",
    "pred_df1 = pd.DataFrame()\n",
    "pred_df2 = pd.DataFrame()\n",
    "pred_df3 = pd.DataFrame()\n",
    "for fold in tqdm(range(5)):\n",
    "    pred_df1[f'fold{fold}'] = run(fold, '../input/roberta-base/', '../input/commonlit-roberta-base-i/')\n",
    "    pred_df2[f'fold{fold+5}'] = run(fold, '../input/robertalarge/', '../input/roberta-large-itptfit/')\n",
    "    pred_df3[f'fold{fold+10}'] = run(fold, '../input/robertalarge/', '../input/commonlit-roberta-large-ii/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "valued-swimming",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-09T10:36:50.978708Z",
     "iopub.status.busy": "2021-06-09T10:36:50.977918Z",
     "iopub.status.idle": "2021-06-09T10:36:51.133757Z",
     "shell.execute_reply": "2021-06-09T10:36:51.132913Z",
     "shell.execute_reply.started": "2021-06-09T10:27:27.553873Z"
    },
    "papermill": {
     "duration": 0.275979,
     "end_time": "2021-06-09T10:36:51.133890",
     "exception": false,
     "start_time": "2021-06-09T10:36:50.857911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample['target'] = (pred_df2.mean(axis=1)*0.35) + (pred_df1.mean(axis=1)*0.20) + (pred_df3.mean(axis=1) * 0.15) + (svm_preds * 0.30)\n",
    "sample.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 518.856753,
   "end_time": "2021-06-09T10:36:54.258163",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-09T10:28:15.401410",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
